{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare FFTLIN with FFTMEL\n",
    "\n",
    "2018-08-09"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_moons, make_circles, make_classification\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decide classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# names = [\"Nearest Neighbors\", \"Linear SVM\", \"RBF SVM\", \"Gaussian Process\",\n",
    "#          \"Decision Tree\", \"Random Forest\", \"Neural Net\", \"AdaBoost\",\n",
    "#          \"Naive Bayes\", \"QDA\"]\n",
    "# classifiers = [\n",
    "#     KNeighborsClassifier(3),\n",
    "#     SVC(kernel=\"linear\", C=0.025),\n",
    "#     SVC(gamma=2, C=1),\n",
    "#     GaussianProcessClassifier(1.0 * RBF(1.0)),\n",
    "#     DecisionTreeClassifier(max_depth=5),\n",
    "#     RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),\n",
    "#     MLPClassifier(alpha=1),\n",
    "#     AdaBoostClassifier(),\n",
    "#     GaussianNB(),\n",
    "#     QuadraticDiscriminantAnalysis()]\n",
    "names = ['Decision Tree','Naive Bayes','Neural Net']\n",
    "classifiers = [\n",
    "    DecisionTreeClassifier(max_depth=10),\n",
    "    GaussianNB(),\n",
    "    MLPClassifier(alpha=1, max_iter=30, verbose=True),]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# (1) FFT with linear filter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "630\n"
     ]
    }
   ],
   "source": [
    "sdict = np.load('spkr_sdict_fftlin.npy').item()\n",
    "print(len(sdict.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 630/630 [00:35<00:00, 17.98it/s]\n"
     ]
    }
   ],
   "source": [
    "# Initiate X, y\n",
    "X = np.array([], dtype=np.float32).reshape((0, 40))\n",
    "y = []\n",
    "for s in tqdm(sdict.keys()):\n",
    "    for v in sdict[s].keys():\n",
    "        data = sdict[s][v]\n",
    "        X = np.vstack([X, data])\n",
    "        y += [s]*data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = StandardScaler().fit_transform(X)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((190526, 40), 190526)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, len(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Divide train/test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    test_size=0.3,\n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:19, 19.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier:Decision Tree, Score:0.031159242800657825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:24, 12.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier:Naive Bayes, Score:0.019472339829945066\n",
      "Iteration 1, loss = 6.38952048\n",
      "Iteration 2, loss = 6.20966407\n",
      "Iteration 3, loss = 6.18972157\n",
      "Iteration 4, loss = 6.18060557\n",
      "Iteration 5, loss = 6.17443215\n",
      "Iteration 6, loss = 6.17111617\n",
      "Iteration 7, loss = 6.16663993\n",
      "Iteration 8, loss = 6.16461749\n",
      "Iteration 9, loss = 6.16285875\n",
      "Iteration 10, loss = 6.16040518\n",
      "Iteration 11, loss = 6.15876718\n",
      "Iteration 12, loss = 6.15689018\n",
      "Iteration 13, loss = 6.15540387\n",
      "Iteration 14, loss = 6.15424658\n",
      "Iteration 15, loss = 6.15288771\n",
      "Iteration 16, loss = 6.15162343\n",
      "Iteration 17, loss = 6.15075664\n",
      "Iteration 18, loss = 6.14978657\n",
      "Iteration 19, loss = 6.14923510\n",
      "Iteration 20, loss = 6.14831543\n",
      "Iteration 21, loss = 6.14747842\n",
      "Iteration 22, loss = 6.14661047\n",
      "Iteration 23, loss = 6.14619852\n",
      "Iteration 24, loss = 6.14540708\n",
      "Iteration 25, loss = 6.14473159\n",
      "Iteration 26, loss = 6.14423240\n",
      "Iteration 27, loss = 6.14384471\n",
      "Iteration 28, loss = 6.14353701\n",
      "Iteration 29, loss = 6.14350607\n",
      "Iteration 30, loss = 6.14320800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zzandore/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "3it [02:48, 56.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier:Neural Net, Score:0.0202596311977326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for name, clf in tqdm(zip(names, classifiers)):\n",
    "    clf.fit(X_train, y_train)\n",
    "    score = clf.score(X_test, y_test)\n",
    "    print(f'Classifier:{name}, Score:{score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# (2) FFT with Mel filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "630\n"
     ]
    }
   ],
   "source": [
    "sdict = np.load('spkr_sdict_fftmel.npy').item()\n",
    "print(len(sdict.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 630/630 [00:26<00:00, 23.87it/s]\n"
     ]
    }
   ],
   "source": [
    "# Initiate X, y\n",
    "X = np.array([], dtype=np.float32).reshape((0, 40))\n",
    "y = []\n",
    "for s in tqdm(sdict.keys()):\n",
    "    for v in sdict[s].keys():\n",
    "        data = sdict[s][v]\n",
    "        X = np.vstack([X, data])\n",
    "        y += [s]*data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = StandardScaler().fit_transform(X)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    test_size=0.3,\n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:18, 18.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier:Decision Tree, Score:0.031421673256587006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:24, 12.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier:Naive Bayes, Score:0.03129920571048672\n",
      "Iteration 1, loss = 6.32337301\n",
      "Iteration 2, loss = 6.09651475\n",
      "Iteration 3, loss = 6.06474535\n",
      "Iteration 4, loss = 6.05155662\n",
      "Iteration 5, loss = 6.04343813\n",
      "Iteration 6, loss = 6.03839883\n",
      "Iteration 7, loss = 6.03447262\n",
      "Iteration 8, loss = 6.03261730\n",
      "Iteration 9, loss = 6.03009385\n",
      "Iteration 10, loss = 6.02723731\n",
      "Iteration 11, loss = 6.02523843\n",
      "Iteration 12, loss = 6.02466297\n",
      "Iteration 13, loss = 6.02265293\n",
      "Iteration 14, loss = 6.02204271\n",
      "Iteration 15, loss = 6.02026316\n",
      "Iteration 16, loss = 6.01956158\n",
      "Iteration 17, loss = 6.01800468\n",
      "Iteration 18, loss = 6.01725033\n",
      "Iteration 19, loss = 6.01597297\n",
      "Iteration 20, loss = 6.01479897\n",
      "Iteration 21, loss = 6.01350466\n",
      "Iteration 22, loss = 6.01313665\n",
      "Iteration 23, loss = 6.01174466\n",
      "Iteration 24, loss = 6.01147209\n",
      "Iteration 25, loss = 6.01084435\n",
      "Iteration 26, loss = 6.01039425\n",
      "Iteration 27, loss = 6.00988269\n",
      "Iteration 28, loss = 6.00883442\n",
      "Iteration 29, loss = 6.00891503\n",
      "Iteration 30, loss = 6.00767575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zzandore/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "3it [02:35, 51.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier:Neural Net, Score:0.03485076454739494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for name, clf in tqdm(zip(names, classifiers)):\n",
    "    clf.fit(X_train, y_train)\n",
    "    score = clf.score(X_test, y_test)\n",
    "    print(f'Classifier:{name}, Score:{score}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
